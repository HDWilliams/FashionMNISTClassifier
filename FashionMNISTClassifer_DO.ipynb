{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FashionMNISTClassifer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HDWilliams/FashionMNISTClassifier/blob/master/FashionMNISTClassifer_DO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFklNs1ja-RO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#needed if running on local machine. This project was made using Colab which does not require this step\n",
        "#!pip install torch torchvision\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zTX2iwqbX4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "8d0379a3-69ab-4c86-da7c-7c0fa734501f"
      },
      "source": [
        "#import relevant dependancies\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#set up transform for a black and white image i.e. size = [1, #, #]\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "#set up trainset and trainloader and apply transform, do same for testset and testloader\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:04, 5769994.30it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 39078.57it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:02, 1716163.34it/s]                             \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 13477.96it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /root/.pytorch/F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFtmatnmktz1",
        "colab_type": "code",
        "outputId": "744e7dc4-6588-4f24-f73c-0927818c8017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#set up GPU training\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_jLAwBvejB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "58c39b06-8d01-4ef1-895a-2d34872c1e6f"
      },
      "source": [
        "#Set up Neural Network\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FashionClassifier(nn.Module):\n",
        "  #envoke __init__ method of parent class\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    #define layers of network, 2 hidden layers and one output layer. All layers are linear\n",
        "    #input of the next layer will be equal to the output of the previous layer as all layers are fully connected\n",
        "    #output layer must have same number of nodes as classes in the dataset\n",
        "    \n",
        "    inp = 784 # 28 X 28 image\n",
        "    hid1 = 128 \n",
        "    hid2 = 64\n",
        "    out = 10 # 10 classes of clothing\n",
        "    self.layer1 = nn.Linear(inp, hid1)\n",
        "    self.layer2 = nn.Linear(hid1, hid2)\n",
        "    self.outputLayer = nn.Linear(hid2, out)\n",
        "    \n",
        "    #drop out to prevent overfitting\n",
        "    self.Dropout = nn.Dropout(p=.2)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.Dropout(F.relu(self.layer1(x)))\n",
        "    x = self.Dropout(F.relu(self.layer2(x)))\n",
        "    \n",
        "    log_softmax = nn.LogSoftmax(dim=1)\n",
        "    output = log_softmax(self.outputLayer(x))\n",
        "    return output\n",
        "\n",
        "model = FashionClassifier()\n",
        "model.to(device)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionClassifier(\n",
              "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (outputLayer): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (Dropout): Dropout(p=0.2)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-362hwthpwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set up optimizer for SGD and criterion for loss function\n",
        "#loss function will be Negative Log Likelihood for multiclass classification \n",
        "\n",
        "#learning rate = lr\n",
        "lr = .05\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6Y-MBODkecZ",
        "colab_type": "code",
        "outputId": "01551cf4-7fbf-4741-e839-970ff6773b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "source": [
        "#train the model\n",
        "epochs = 25\n",
        "loss_by_epoch = []\n",
        "for epoch in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images, labels in trainloader:\n",
        "    #reshape images into expected 2D\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    #send images and labels to device for potential GPU training if available \n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "    \n",
        "    output = model(images)\n",
        "    loss = criterion(output, labels)\n",
        "    \n",
        "    #calculate gradients and backpropagate \n",
        "    loss.backward()\n",
        "    \n",
        "    #take step using SGD\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "  #print loss every epoch\n",
        "  loss_by_epoch.append(running_loss)\n",
        "  print ('Loss: ', running_loss / len(trainloader))\n",
        "print(loss_by_epoch)\n",
        "    \n",
        "    \n",
        "    \n",
        "  "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss:  0.2913553770909558\n",
            "Loss:  0.2821006122380813\n",
            "Loss:  0.2792581195500233\n",
            "Loss:  0.27412770238162865\n",
            "Loss:  0.2722510958372403\n",
            "Loss:  0.26761628470536486\n",
            "Loss:  0.26435852032512236\n",
            "Loss:  0.26094895795082995\n",
            "Loss:  0.25889775651826785\n",
            "Loss:  0.25311797530825203\n",
            "Loss:  0.25209863379851843\n",
            "Loss:  0.24985804420703256\n",
            "Loss:  0.24751620506967054\n",
            "Loss:  0.24294868668418196\n",
            "Loss:  0.24018737869158482\n",
            "Loss:  0.23673706483453322\n",
            "Loss:  0.23378623303955298\n",
            "Loss:  0.23434674140137396\n",
            "Loss:  0.23102239964962767\n",
            "Loss:  0.22796293984312238\n",
            "Loss:  0.22852365741692882\n",
            "Loss:  0.2229721834505799\n",
            "Loss:  0.21975984314738561\n",
            "Loss:  0.2196139744095711\n",
            "Loss:  0.21760240156672148\n",
            "[273.2913437113166, 264.61037427932024, 261.9441161379218, 257.1317848339677, 255.37152789533138, 251.02407505363226, 247.96829206496477, 244.7701225578785, 242.84609561413527, 237.42466083914042, 236.46851850301027, 234.36684546619654, 232.17020035535097, 227.88586810976267, 225.29576121270657, 222.05936681479216, 219.2914865911007, 219.81724343448877, 216.69901087135077, 213.8292375728488, 214.35519065707922, 209.14790807664394, 206.1347328722477, 205.99790799617767, 204.11105266958475]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khLlQilZAK3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test Network\n",
        "\n",
        "#Visualization help functions from GitHub: https://github.com/iArunava/Intro-to-Deep-Learning-with-Pytorch-Udacity-Solutions/blob/master/intro-to-pytorch/Part%204%20-%20Fashion-MNIST.ipynb\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_yticklabels(np.arange(10))\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_yticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    \n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "### end of visulaization helper functions\n",
        "\n",
        "def viewNumImg(numImgs):\n",
        "  model.eval()\n",
        "  data = iter(testloader)\n",
        "  images, labels = data.next()\n",
        "\n",
        "  for img in images[0:numImgs]:\n",
        "    # Convert 2D image to 1D vector\n",
        "    img = img.view(1, -1)\n",
        "\n",
        "    # TODO: Calculate the class probabilities (softmax) for img\n",
        "    ps = torch.exp(model(img))\n",
        "    print (ps)\n",
        "\n",
        "    # Plot the image and probabilities\n",
        "    #helper.view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
        "    view_classify(img.resize_(1, 28, 28), ps, version='Fashion')\n",
        "  model.train()\n",
        "\n",
        "viewNumImg(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJmaxhMIh_Jx",
        "colab_type": "code",
        "outputId": "bcc918a7-bd6d-4cab-8eac-cad35cec3edc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#Validation: get validation accuracy on test set\n",
        "accuracy = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  for images, labels in testloader:\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    \n",
        "    #send tensors to device\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "    ps=torch.exp(model(images))\n",
        "    topk, top_class = ps.topk(1, dim=1)\n",
        "    results = top_class == labels.view(top_class.shape[0],1)\n",
        "    accuracy += torch.mean(results.type(torch.FloatTensor))\n",
        "print('Accuracy: ', (accuracy.item()/len(testloader))*100, '%')\n",
        "model.train()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  87.36066878980891 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionClassifier(\n",
              "  (layer1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (layer2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (outputLayer): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (Dropout): Dropout(p=0.2)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}